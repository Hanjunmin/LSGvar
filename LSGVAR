#!/usr/bin/env python3

# -*- coding: us-ascii -*-
"""
Created on Thurs April 3 10:56 2025
@Author: Feifei Zhou
"""

import json
import sys
import logging
import shutil
import argparse
import subprocess
from pathlib import Path
from utils import process_paf, run_minimap, process_filtering, run_cluster_and_call, run_cigar_processing, run_dup_filtering, generate_vcf, split_vcf, integrate_results

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
def check_file_exists(file_path):
    return Path(file_path).exists()

def LSGvar(args):
    # make output directory
    output_dir = Path("results")
    output_dir.mkdir(exist_ok=True)

    ## Check the alignments file, and then preprocess the alignments file
    ## If there doesn't have paf file, then align first
    logging.info("1.Filter")
    if args.paf1:
        output_file = f"align_hap1.flt.paf"
        if not check_file_exists(output_file):
            try:
                process_paf(args.paf1, args.pairs1, "hap1")
            except Exception as e:
                logging.error(f"Error in process_paf for hap1: {e}")
                sys.exit(1)
    else:
        paf_file = f"align_hap1.paf"
        if not check_file_exists(paf_file):
            try:
                logging.info("Running minimap2 for hap1 alignment")
                run_minimap(args.ref, args.hap1, "hap1", args.pairs1)
            except Exception as e:
                logging.error(f"Error in run_minimap for hap1: {e}")
                sys.exit(1)

    final_paf_file = f"align_hap1.final.paf"
    if not check_file_exists(final_paf_file):
        try:
            process_filtering("hap1", args.mode, args.cluster, args.dellength, args.centromere, args.telomere)
        except Exception as e:
            logging.error(f"Error in process_filtering for hap1: {e}")
            sys.exit(1)

    if args.hap2:
        if args.paf2:
            output_file = f"align_hap2.flt.paf"
            if not check_file_exists(output_file):
                try:
                    process_paf(args.paf2, args.pairs2, "hap2")
                except Exception as e:
                    logging.info(f"Error in process_paf for hap2: {e}")
                    sys.exit(1)
        else:
            
            paf_file = f"align_hap2.paf"
            if not check_file_exists(paf_file):
                try:
                    logging.info("Running minimap2 for hap2 alignment")
                    run_minimap(args.ref, args.hap2, "hap2", args.pairs2)
                except Exception as e:
                    logging.error(f"Error in run_minimap for hap2: {e}")
                    sys.exit(1)

        final_paf_file = f"align_hap2.final.paf"
        if not check_file_exists(final_paf_file):
            try:
                process_filtering("hap2", args.mode, args.cluster, args.dellength, args.centromere, args.telomere)
            except Exception as e:
                logging.error(f"Error in process_filtering for hap2: {e}")
                sys.exit(1)

    ## SV calling
    logging.info("2.Variants calling")
    sdrall_file = Path(f"denSDRhap1")/"SDRall_final.txt"
    if not check_file_exists(sdrall_file):
        try:
            run_cluster_and_call(args.ref, args.hap1, "hap1", args.invcluster, args.threads, args.chunk_size, args.distance)
        except Exception as e:
            logging.error(f"Error in run_cluster_and_call for hap1: {e}")
            sys.exit(1)

    if args.hap2:
        sdrall_file = Path(f"denSDRhap2")/"SDRall_final.txt"
        if not check_file_exists(sdrall_file):
            try:
                run_cluster_and_call(args.ref, args.hap2, "hap2", args.invcluster, args.threads, args.chunk_size, args.distance)
            except Exception as e:
                logging.error(f"Error in run_cluster_and_call for hap2: {e}")
                sys.exit(1)

    ## INDEL, SNV and SV calling from CIGAR
    cigar_end_file = Path(f"half")/"hap1cigarend.txt"
    if not check_file_exists(cigar_end_file):
        try:
            run_cigar_processing(args.ref, args.hap1, "hap1")
        except Exception as e:
            logging.error(f"Error in run_cigar_processing for hap1: {e}")
            sys.exit(1)

    if args.hap2:
        cigar_end_file = Path(f"half")/"hap2cigarend.txt"
        if not check_file_exists(cigar_end_file):
            try:
                run_cigar_processing(args.ref, args.hap2, "hap2")
            except Exception as e:
                logging.error(f"Error in run_cigar_processing for hap2: {e}")
                sys.exit(1)

    ## Dup filter
    cigarout_file = Path(f"half")/"hap1cigarout.txt"
    cigarend_file = Path(f"half")/"hap1cigarend.txt"
    if not check_file_exists(cigarout_file):
        try:
            run_dup_filtering("hap1")
        except Exception as e:
            logging.error(f"Error in run_dup_filtering for hap1: {e}")
            sys.exit(1)

    if args.hap2:
        cigarout_file = Path(f"half")/"hap2cigarout.txt"
        cigarend_file = Path(f"half")/"hap2cigarend.txt"
        if not check_file_exists(cigarout_file):
            try:
                run_dup_filtering("hap2")
            except Exception as e:
                logging.error(f"Error in run_dup_filtering for hap2: {e}")
                sys.exit(1)

    ## Generate vcf and bed
    logging.info("3.Generate")
    vcf_file = Path(f"results") / f"hap1cigarsdr.vcf"
    if not check_file_exists(vcf_file):
        try:
            generate_vcf(args.ref, args.hap1, "hap1")
        except Exception as e:
            logging.error(f"Error in generate_vcf for hap1: {e}")
            sys.exit(1)

    if args.hap2:
        vcf_file = Path(f"results") / f"hap2cigarsdr.vcf"
        if not check_file_exists(vcf_file):
            try:
                generate_vcf(args.ref, args.hap2, "hap2")
            except Exception as e:
                logging.error(f"Error in generate_vcf for hap2: {e}")
                sys.exit(1)

    hap_dir = Path(f"hap1")
    split_check_file = hap_dir / "sortindel.vcf.gz"  
    if not check_file_exists(split_check_file):
        try:
            split_vcf("hap1")
        except Exception as e:
            logging.error(f"Error in split_vcf for hap1: {e}")
            sys.exit(1)

    if args.hap2:
        hap_dir = Path(f"hap2")
        split_check_file = hap_dir / "sortindel.vcf.gz"  
        if not check_file_exists(split_check_file):
            try:
                split_vcf("hap2")
            except Exception as e:
                logging.error(f"Error in split_vcf for hap2: {e}")
                sys.exit(1)

    if args.hap2:
        logging.info("4.Phenotype")
        result_dir = Path("results")
        final_bed = result_dir / "LSGvar.bed"  # Check for the existence of the final output
        if not check_file_exists(final_bed):
            try:
                integrate_results("hap1", "hap2", args.sample_name, args.max_distance, args.small_distance, args.similarity_threshold)
            except Exception as e:
                logging.error(f"Error in integrate_results: {e}")
                sys.exit(1)
    #remove_temp_files()
def main():

    ascii_art = [
    r"\033[38;5;97m╔════════════════════════════════════════════════════════╗\033[0m",
    r"\033[38;5;97m║                                                        ║\033[0m",
    r"\033[38;5;97m║   \033[38;5;205m██╗     ███████╗ ██████╗ ██╗   ██╗ █████╗ ██████╗\033[38;5;97m    ║\033[0m",
    r"\033[38;5;97m║   \033[38;5;209m██║     ██╔════╝██╔════╝ ██║   ██║██╔══██╗██╔══██╗\033[38;5;97m   ║\033[0m",
    r"\033[38;5;97m║   \033[38;5;214m██║     ███████╗██║  ███╗██║   ██║███████║██████╔╝\033[38;5;97m   ║\033[0m",
    r"\033[38;5;97m║   \033[38;5;220m██║     ╚════██║██║   ██║██║   ██║██╔══██║██╔══██╗\033[38;5;97m   ║\033[0m",
    r"\033[38;5;97m║   \033[38;5;226m███████╗███████║╚██████╔╝╚██████╔╝██║  ██║██║  ██║\033[38;5;97m   ║\033[0m",
    r"\033[38;5;97m║   \033[38;5;46m╚══════╝╚══════╝ ╚═════╝  ╚═════╝ ╚═╝  ╚═╝╚═╝  ╚═╝\033[38;5;97m   ║\033[0m",
    r"\033[38;5;97m║                                                        ║\033[0m",
    r"\033[38;5;97m║    \033[38;5;51m                   L S G V A R                   \033[38;5;97m   ║\033[0m",
    r"\033[38;5;97m╚════════════════════════════════════════════════════════╝\033[0m"
    ]

    for line in ascii_art:
        colored_line = line.replace(r"\033[", "\033[")
        print(colored_line)

    print("\nLarge-Scale Genetic VARiation caller\n")
    print("\nRun command:")
    print("LSGVAR -r ref.fa -q1 hap1.fa -q2 hap2.fa -p1 hap1.paf -p2 hap2.paf -cp1 PTR_hap1_pair.tsv -cp2 PTR_hap2_pair.tsv -cen chm13_cen.tsv -telo chm13_telo.tsv -m cts -s PTR\n")
    
    parser = argparse.ArgumentParser()
    required = parser.add_argument_group("Input Files")

    required.add_argument('-r', '--ref', required=True, help='Reference genome for variants calling')
    required.add_argument('-q1', '--hap1', required=True, help='One query genome (Which is one haplotype of one species genome and needs to be scaffolded to chromosome level using RagTag to ensure better genome quality for more reliable variant calling results.)')
    required.add_argument('-q2', '--hap2', help='Another query genome (Which is another haplotype of the species genome and needs to be scaffolded to chromosome level using RagTag to ensure better genome quality for more reliable variant calling results.)')
    required.add_argument('-p1', '--paf1', help='Alignment of haplotype1 (Which contains the CIGAR infomation) [Recommend mapping tool: minimap2].')
    required.add_argument('-p2', '--paf2', help='Alignment for haplotype2 (Which contains the CIGAR infomation) [Recommend mapping tool: minimap2].')
    required.add_argument('-cp1', '--pairs1', required=True, help='Homologous chromsome pairs of query genome (hap1) and reference.')
    required.add_argument('-cp2', '--pairs2', help='Homologous chromsome pairs of query genome (hap2) and reference.')
    required.add_argument('-c', '--cluster', type=int, default=200000, help='Clustering parameter for filtering chaos alignments, where a smaller value results in a stricter filter [200000].')
    required.add_argument('-dl', '--dellength', type=int, default=300000, help='A desired deletion length for alignments, where a larger value enforces a stricter filter [300000].')
    required.add_argument('-inv', '--invcluster', type=int, default=700000, help='Clustering parameter for inversion calling [700000].')
    required.add_argument('-cen', '--centromere', required=False, help='A centromere file which is used to filter out the alignment of complex regions that may not be well aligned [False].')
    required.add_argument('-telo', '--telomere', required=False, help='A telomere file which is used to filter out the alignment of complex regions that may not be well aligned [False].')
    required.add_argument('-m', '--mode', choices=['ctn', 'cts'], required=True,
                        help='Analysis mode: ctn (do not remove centromere and telomere alignments) or cts (remove) [ctn].')
    required.add_argument('-d', '--distance', type=int, default=0, help='Parameters used to identify INS and DEL: Variations where the distance between the start and end positions of the REF or QUERY is less than (or equal with) d will be identified as SVs. A lower value indicates stricter criteria for SV identification [0bp].')
    required.add_argument('-t', '--threads', type=int, default=4, help='Multi threads for inversion re-identification from SDR.')
    required.add_argument('-k', '--chunk_size', type=int, default=50, help='Process line of each thread in inversion re-identification.')
    required.add_argument('-s', '--sample_name', type=str, default="SAMPLE", help='Sample name used to generate vcf.')
                        
    ## Parameters for generating results
    merge = parser.add_argument_group("Additional arguments")
    merge.add_argument('-mdist', '--max_distance', type=int, default=500, 
                       help='Max reference distance for two allele to merge [500bp].')
    merge.add_argument('-sdist', '--small_distance', type=int, default=10, 
                       help='Max reference distance for SSV (small variants) merge [10bp].')
    merge.add_argument('-sim', '--similarity_threshold', type=float, default=0.8, 
                       help='The similarity of variants, used to merge the variants of two haplotypes [0.8].')
    args = parser.parse_args()
    LSGvar(args)

if __name__ == "__main__":
    main()
